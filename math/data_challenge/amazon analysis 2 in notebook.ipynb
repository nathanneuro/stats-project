{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Python is not installed as a framework. The Mac OS X backend will not be able to function correctly if Python is not installed as a framework. See the Python documentation for more information on installing Python as a framework on Mac OS X. Please either reinstall Python as a framework, or try one of the other backends. If you are Working with Matplotlib in a virtual enviroment see 'Working with Matplotlib in Virtual environments' in the Matplotlib FAQ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5dac4c99c5f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msqlalchemy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# select product, ratings, average rating from table where number of reviews >= 1000 GroupBy productID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nathanhelm-burger/.pyenv/versions/venv34math/lib/python3.4/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpylab_setup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m \u001b[0m_backend_mod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_figure_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdraw_if_interactive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_show\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpylab_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0m_IP_REGISTERED\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nathanhelm-burger/.pyenv/versions/venv34math/lib/python3.4/site-packages/matplotlib/backends/__init__.py\u001b[0m in \u001b[0;36mpylab_setup\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# imports. 0 means only perform absolute imports.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     backend_mod = __import__(backend_name,\n\u001b[0;32m---> 32\u001b[0;31m                              globals(),locals(),[backend_name],0)\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Things we pull in from all backends\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nathanhelm-burger/.pyenv/versions/venv34math/lib/python3.4/site-packages/matplotlib/backends/backend_macosx.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_macosx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Python is not installed as a framework. The Mac OS X backend will not be able to function correctly if Python is not installed as a framework. See the Python documentation for more information on installing Python as a framework on Mac OS X. Please either reinstall Python as a framework, or try one of the other backends. If you are Working with Matplotlib in a virtual enviroment see 'Working with Matplotlib in Virtual environments' in the Matplotlib FAQ"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "np.set_printoptions(precision=9)\n",
    "import math\n",
    "import timeit\n",
    "import gzip\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# select product, ratings, average rating from table where number of reviews >= 1000 GroupBy productID\n",
    "\n",
    "# I will select 5 or 10 ratings at random from the test products to use as predictors for the average rating\n",
    "# check the scikit-learn tutorial for how to predict a continuous variable\n",
    "\n",
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "\n",
    "def Load_Review_Chunk(path, destination, chunksize):\n",
    "  start_time = timeit.default_timer()\n",
    "  dfDict = {}\n",
    "  i = 22645001\n",
    "  chunk = 4530\n",
    "  for d in parse(path):\n",
    "      dfDict[i] = d\n",
    "      i += 1\n",
    "      if i > chunksize * chunk:\n",
    "        chunk_to_SQL(dfDict, destination)\n",
    "        print(\"Chunk #\", chunk, \" saved. Time elapsed: \", int(timeit.default_timer() - start_time), \" seconds\", end='\\r')\n",
    "        dfDict = {}\n",
    "        chunk += 1\n",
    "  chunk_to_SQL(dfDict, destination)\n",
    "  print(\"Last Chunk #\", chunk, \"Total time elapsed: \", int(timeit.default_timer() - start_time), \" seconds\", end='\\r')\n",
    "  return\n",
    "\n",
    "\n",
    "def chunk_to_SQL(dfDict, destination):\n",
    "  df = pd.DataFrame.from_dict(dfDict, orient='index')\n",
    "  # I can use reviewTime or unixReviewTime to select first 10 reviews to train on\n",
    "  # maybe I'll keep reviewerID so I can rematch with reviewText if I want to\n",
    "  df.drop(['helpful', 'reviewText', 'reviewerName', 'summary', 'reviewTime'], axis=1, inplace = True)\n",
    "  #print(df.head())\n",
    "  #print(df.head())\n",
    "  df.to_sql('reviews', disk_engine, if_exists='append', index_label = 'index')\n",
    "  return\n",
    "\n",
    "def step2():\n",
    "  df = pd.DataFrame\n",
    "  # make list of unique asin\n",
    "  sql = \"SELECT DISTINCT asin FROM subset\"\n",
    "  asinList = pd.read_sql_query(sql, disk_engine)\n",
    "  print(asinList.head())\n",
    "  print(len(asinList.index))\n",
    "  for row in asinList['asin'].tolist():\n",
    "    print(\"loading: \", row)\n",
    "    sql = \"SELECT * FROM subset WHERE asin = '\" + row + \"' LIMIT 20\"\n",
    "    temp_df = pd.read_sql_query(sql, disk_engine, index_col = 'index')\n",
    "    print(\"Temp df:\\n\", temp_df.head())\n",
    "    if len(temp_df.index)>1:\n",
    "      print(\"appending temp_df to df\")\n",
    "      if df.empty:\n",
    "        df = temp_df\n",
    "      else:\n",
    "        df = df.append(temp_df, ignore_index=True)\n",
    "    \n",
    "  print(df.head(), df.tail())\n",
    "\n",
    "\n",
    "  # df = pd.read_sql_query(sql, disk_engine, index_col = 'index')\n",
    "  # print(df.head())\n",
    "  \n",
    "  #df.to_sql('means', disk_engine, if_exists='replace', index_label = 'index')\n",
    "  df.to_csv(text_destination)\n",
    "  print(\"Success! Hooray!\")\n",
    "  return\n",
    "\n",
    "def step3(text_source, text_destination):\n",
    "  # find average overall from data for each asin, and load to df1\n",
    "  sql = \"SELECT asin, avg(overall) FROM subset GROUP BY asin\"\n",
    "  df1 =  pd.read_sql_query(sql, disk_engine)\n",
    "\n",
    "  # load the ratings into df2\n",
    "  df2 = pd.read_csv(text_source)\n",
    "\n",
    "  # join on asin, keeping just df2 (left)\n",
    "  df = pd.merge(df2, df1, on='asin', how='left')\n",
    "\n",
    "  # resave\n",
    "  print(df.head(), df.tail())\n",
    "  df.to_csv(text_destination)\n",
    "  print(\"Step 3 Successful! Hooray!\")\n",
    "  return\n",
    "\n",
    "def step4(text_source, text_destination):\n",
    "  # find average of just first 20 ratings\n",
    "  df = pd.read_csv(text_source)\n",
    "  df['avg20'] = df['overall'].groupby(df['asin']).transform(np.mean)\n",
    "  # save as new file\n",
    "  print(df.head(), df.tail())\n",
    "  df.to_csv(text_destination)\n",
    "  print(\"step 4 successful!\")\n",
    "  return\n",
    "\n",
    "def step5(text_source):\n",
    "  # scatterplot with trend line, x=avg20, y=avg(overall)\n",
    "  df = pd.read_csv(text_source)\n",
    "  df.plot(kind='scatter', x='avg20', y='avg(overall)')\n",
    "\n",
    "  return\n",
    "\n",
    "def main():\n",
    "  path = '/Volumes/Storage/Lab data/Data Analysis/metadata.json.gz'\n",
    "  database = '/Volumes/STORAGECARD/ratingsForReviewsOver1000.db'\n",
    "  text_source = '/Volumes/STORAGECARD/ratingsAverage.csv'\n",
    "  text_destination = '/Volumes/STORAGECARD/ratingsAverage.csv'\n",
    "\n",
    "  global disk_engine\n",
    "  disk_engine = create_engine('sqlite:///' + database)\n",
    "  \n",
    "  # Step 1\n",
    "  # Load_Review_Chunk(path, destination, 5000)\n",
    "  # print(df.head())\n",
    "  # print(\"Review Chunk #\", chunk, \"chunk size\", df.size)\n",
    "  # print(\"total size\", df.size)\n",
    "  # group by asin\n",
    "  # select asin where asin rows >= 1000\n",
    "  # grouped = df.groupby(['asin']).filter(lambda x: len(x)>=1000)\n",
    "  # print(\"grouped size\", grouped.size)\n",
    "  \n",
    "  #sql = \"SELECT * FROM reviews LIMIT 5 OFFSET (SELECT COUNT(*) FROM reviews)-5\"\n",
    "  #df = pd.read_sql_query(sql, disk_engine, index_col = 'index')\n",
    "  #print(df.head())\n",
    "\n",
    "  # what I want seems too complex, so breaking it down.. means as separate table, then join\n",
    "\n",
    "  # would be better to combine this query with the next one rather than creating a subset table, so I don't have to redo after finishing populating database\n",
    "  # for now, it gives me something to practice on\n",
    "\n",
    "  #step 2?\n",
    "\n",
    "  #sql = \"CREATE TABLE subset AS SELECT * FROM reviews WHERE asin IN ( SELECT asin FROM reviews GROUP BY asin HAVING COUNT (asin)>999)\"\n",
    "  #disk_engine.execute(sql)\n",
    "  #print(\"new table created\")\n",
    "  #sql = \"SELECT * FROM subset a WHERE a.'index' IN ( SELECT b.'index' FROM subset b WHERE b.'index' IS NOT NULL AND a.'asin' = b.'asin' ORDER BY b.'unixReviewTime', b.'index' LIMIT 20) ORDER BY a.'asin', a.'unixReviewTime'\" \n",
    "  \n",
    "  #step3(text_source, text_destination)\n",
    "\n",
    "  #step4(text_source, text_destination)\n",
    "\n",
    "  step5(text_source)\n",
    "\n",
    "  return\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "   main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
